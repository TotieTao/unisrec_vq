import copy
import torch
import torch.nn as nn
import torch.nn.functional as F
from recbole.model.sequential_recommender.sasrec import SASRec
from model.module.group_dict_ym import InterestDict, InterestDictSoft,InterestDictSoft_uni,InterestDictSoft_euc,InterestDictSoft_euc2,InterestDictSoft_cosv2,InterestDictSoft_coarse
from model.loss import contrastive_ccloss
from model.loss import contrastive_loss
from util.tensor_op import GeLU
import math
from model.module.Kmeans import KMeans_Pytorch,KMeans,run_kmeans_pcl

class PWLayer(nn.Module):
    """Single Parametric Whitening Layer
    """
    def __init__(self, input_size, output_size, dropout=0.0):
        super(PWLayer, self).__init__()

        self.dropout = nn.Dropout(p=dropout)
        self.bias = nn.Parameter(torch.zeros(input_size), requires_grad=True)
        self.lin = nn.Linear(input_size, output_size, bias=False)

        self.apply(self._init_weights)

    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            module.weight.data.normal_(mean=0.0, std=0.02)

    def forward(self, x):
        return self.lin(self.dropout(x) - self.bias)


class MoEAdaptorLayer(nn.Module):
    """MoE-enhanced Adaptor
    """
    def __init__(self, n_exps, layers, dropout=0.0, noise=True):
        super(MoEAdaptorLayer, self).__init__()

        self.n_exps = n_exps
        self.noisy_gating = noise

        self.experts = nn.ModuleList([PWLayer(layers[0], layers[1], dropout) for i in range(n_exps)])
        self.w_gate = nn.Parameter(torch.zeros(layers[0], n_exps), requires_grad=True)
        self.w_noise = nn.Parameter(torch.zeros(layers[0], n_exps), requires_grad=True)

    def noisy_top_k_gating(self, x, train, noise_epsilon=1e-2):
        clean_logits = x @ self.w_gate
        if self.noisy_gating and train:
            raw_noise_stddev = x @ self.w_noise
            noise_stddev = ((F.softplus(raw_noise_stddev) + noise_epsilon))
            noisy_logits = clean_logits + (torch.randn_like(clean_logits).to(x.device) * noise_stddev)
            logits = noisy_logits
        else:
            logits = clean_logits

        gates = F.softmax(logits, dim=-1)
        return gates

    def forward(self, x):
        gates = self.noisy_top_k_gating(x, self.training) # (B, n_E)
        expert_outputs = [self.experts[i](x).unsqueeze(-2) for i in range(self.n_exps)] # [(B, 1, D)]
        expert_outputs = torch.cat(expert_outputs, dim=-2)
        multiple_outputs = gates.unsqueeze(-1) * expert_outputs
        return multiple_outputs.sum(dim=-2)


def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor


def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (Tensor, float, float, float, float) -> Tensor
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)

class UniSRec(SASRec):
    def __init__(self, config, dataset):
        super().__init__(config, dataset)

        self.config = config
        self.train_stage = config['train_stage']
        self.temperature = config['temperature']
        self.lam = config['lambda']

        assert self.train_stage in [
            'pretrain', 'inductive_ft', 'transductive_ft', 'finetune'
        ], f'Unknown train stage: [{self.train_stage}]'

        if self.train_stage in ['pretrain', 'inductive_ft', 'finetune']:
            self.item_embedding = None
            # for `transductive_ft`, `item_embedding` is defined in SASRec base model
        if self.train_stage in ['inductive_ft', 'transductive_ft']:
            # `plm_embedding` in pre-train stage will be carried via dataloader
            self.plm_embedding = copy.deepcopy(dataset.plm_embedding)

        self.moe_adaptor = MoEAdaptorLayer(
            config['n_exps'],
            config['adaptor_layers'],
            config['adaptor_dropout_prob']
        )
        '''group dict'''
        self.group_dict = InterestDictSoft_uni(int(config["long_num_cluster"]), config["adaptor_output_size"], topK=config["proto_topK"])
        self.cur_step = 0
        self.train_epoch = 0
        ### Kmeans
        self.proto_dict = []
        self.proj_head1_1 = nn.Sequential(
            nn.Linear(config["projection_size"], config["projection_size"], bias=True),
                nn.LayerNorm(config["projection_size"], eps=1e-12),
                # nn.ReLU(inplace=True),
                GeLU(),
                nn.Linear(config["projection_size"], config["projection_size"], bias=True),
                nn.LayerNorm(config["projection_size"], eps=1e-12)
        )
        self.proj_head1_1.apply(self._init_weights)
        # self.proj_head3 = nn.Sequential(
        #     nn.Linear(config["adaptor_output_size"], config["projection_size"], bias=True),
        #     nn.LayerNorm(config["projection_size"], eps=1e-12),
        #     # nn.ReLU(inplace=True),
        #     GeLU(),
        #     nn.Linear(config["projection_size"], config["projection_size"], bias=True),
        #     nn.LayerNorm(config["projection_size"], eps=1e-12)
        # )
        # self.proj_head3.apply(self._init_weights)



    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            trunc_normal_(m.weight, std=.02)
            if isinstance(m, nn.Linear) and m.bias is not None:
                nn.init.constant_(m.bias, 0)

    def forward(self, item_seq, item_emb, item_seq_len):
        position_ids = torch.arange(item_seq.size(1), dtype=torch.long, device=item_seq.device)
        position_ids = position_ids.unsqueeze(0).expand_as(item_seq)
        position_embedding = self.position_embedding(position_ids)

        input_emb = item_emb + position_embedding
        if self.train_stage == 'transductive_ft':
            input_emb = input_emb + self.item_embedding(item_seq)
        input_emb = self.LayerNorm(input_emb)
        input_emb = self.dropout(input_emb)

        extended_attention_mask = self.get_attention_mask(item_seq)

        trm_output = self.trm_encoder(input_emb, extended_attention_mask, output_all_encoded_layers=True)
        output = trm_output[-1]
        output = self.gather_indexes(output, item_seq_len - 1)
        return output  # [B H]

    def seq_item_contrastive_task(self, seq_output, same_pos_id, interaction):
        pos_items_emb = self.moe_adaptor(interaction['pos_item_emb'])
        pos_items_emb = F.normalize(pos_items_emb, dim=1)

        pos_logits = (seq_output * pos_items_emb).sum(dim=1) / self.temperature
        pos_logits = torch.exp(pos_logits)

        neg_logits = torch.matmul(seq_output, pos_items_emb.transpose(0, 1)) / self.temperature
        neg_logits = torch.where(same_pos_id, torch.tensor([0], dtype=torch.float, device=same_pos_id.device), neg_logits)
        neg_logits = torch.exp(neg_logits).sum(dim=1)

        loss = -torch.log(pos_logits / neg_logits)
        return loss.mean()

    def v1_seq_item_contrastive_task(self, seq_output, same_pos_id, interaction, pos_item_emb_name):
        pos_items_emb = self.moe_adaptor(interaction[pos_item_emb_name])
        pos_items_emb = F.normalize(pos_items_emb, dim=1)

        pos_logits = (seq_output * pos_items_emb).sum(dim=1) / self.temperature
        pos_logits = torch.exp(pos_logits)

        neg_logits = torch.matmul(seq_output, pos_items_emb.transpose(0, 1)) / self.temperature
        neg_logits = torch.where(same_pos_id, torch.tensor([0], dtype=torch.float, device=same_pos_id.device), neg_logits)
        neg_logits = torch.exp(neg_logits).sum(dim=1)

        loss = -torch.log(pos_logits / neg_logits)
        return loss.mean()

    def seq_seq_contrastive_task(self, seq_output, same_pos_id, interaction):
        item_seq_aug = interaction[self.ITEM_SEQ + '_aug']
        item_seq_len_aug = interaction[self.ITEM_SEQ_LEN + '_aug']
        item_emb_list_aug = self.moe_adaptor(interaction['item_emb_list_aug'])
        seq_output_aug = self.forward(item_seq_aug, item_emb_list_aug, item_seq_len_aug)
        seq_output_aug = F.normalize(seq_output_aug, dim=1)

        pos_logits = (seq_output * seq_output_aug).sum(dim=1) / self.temperature
        pos_logits = torch.exp(pos_logits)

        neg_logits = torch.matmul(seq_output, seq_output_aug.transpose(0, 1)) / self.temperature
        neg_logits = torch.where(same_pos_id, torch.tensor([0], dtype=torch.float, device=same_pos_id.device), neg_logits)
        neg_logits = torch.exp(neg_logits).sum(dim=1)

        loss = -torch.log(pos_logits / neg_logits)
        return loss.mean()

    def v1_seq_seq_contrastive_task(self, seq_output, same_pos_id, interaction, item_seq_type, item_seq_len_type, item_emb_list_type):
        item_seq_aug = interaction[item_seq_type + '_aug']
        item_seq_len_aug = interaction[item_seq_len_type + '_aug']
        item_emb_list_aug = self.moe_adaptor(interaction[item_emb_list_type + '_aug'])
        seq_output_aug = self.forward(item_seq_aug, item_emb_list_aug, item_seq_len_aug)
        seq_output_aug = F.normalize(seq_output_aug, dim=1)

        pos_logits = (seq_output * seq_output_aug).sum(dim=1) / self.temperature
        pos_logits = torch.exp(pos_logits)

        neg_logits = torch.matmul(seq_output, seq_output_aug.transpose(0, 1)) / self.temperature
        neg_logits = torch.where(same_pos_id, torch.tensor([0], dtype=torch.float, device=same_pos_id.device), neg_logits)
        neg_logits = torch.exp(neg_logits).sum(dim=1)

        loss = -torch.log(pos_logits / neg_logits)
        return loss.mean()

    def sl_seq_seq_contrastive_task(self, user_proj_h, user_proj_s, user_proj_l):

        # user_proj_h = self.proj_head3(user_proj_h)
        # user_proj_s = self.proj_head3(user_proj_s)
        # user_proj_l = self.proj_head3(user_proj_l)

        short_poolingloss1 = contrastive_loss('infonce', user_proj_h, user_proj_s,
                                              temperature=self.temperature,
                                              is_print="poolingCL")
        short_poolingloss2 = contrastive_loss('infonce', user_proj_s, user_proj_h,
                                              temperature=self.temperature)
        short_poolingloss = (short_poolingloss1 + short_poolingloss2) / 2

        long_poolingloss1 = contrastive_loss('infonce', user_proj_h, user_proj_l, temperature=self.temperature,
                                             is_print="poolingCL")
        long_poolingloss2 = contrastive_loss('infonce', user_proj_l, user_proj_h, temperature=self.temperature)
        long_poolingloss = (long_poolingloss1 + long_poolingloss2) / 2

        loss = short_poolingloss * 0.25 + long_poolingloss

        return loss


    def pretrain(self, interaction):
        item_seq = interaction[self.ITEM_SEQ]
        item_seq_len = interaction[self.ITEM_SEQ_LEN]
        item_emb_list = self.moe_adaptor(interaction['item_emb_list'])
        seq_output = self.forward(item_seq, item_emb_list, item_seq_len)
        seq_output = F.normalize(seq_output, dim=1)

        # Remove sequences with the same next item
        pos_id = interaction['item_id']
        same_pos_id = (pos_id.unsqueeze(1) == pos_id.unsqueeze(0))
        same_pos_id = torch.logical_xor(same_pos_id, torch.eye(pos_id.shape[0], dtype=torch.bool, device=pos_id.device))

        loss_seq_item = self.seq_item_contrastive_task(seq_output, same_pos_id, interaction)
        loss_seq_seq = self.seq_seq_contrastive_task(seq_output, same_pos_id, interaction)

        loss = loss_seq_item + self.lam * loss_seq_seq
        return loss

    def v1_pretrain(self, interaction, item_id_type, item_seq_type, item_seq_len_type, item_emb_list_type, pos_item_emb_type):
        item_seq = interaction[item_seq_type]
        item_seq_len = interaction[item_seq_len_type]
        item_emb_list = self.moe_adaptor(interaction[item_emb_list_type])
        seq_output = self.forward(item_seq, item_emb_list, item_seq_len)
        seq_output = F.normalize(seq_output, dim=1)

        # Remove sequences with the same next item
        pos_id = interaction[item_id_type]
        same_pos_id = (pos_id.unsqueeze(1) == pos_id.unsqueeze(0))
        same_pos_id = torch.logical_xor(same_pos_id, torch.eye(pos_id.shape[0], dtype=torch.bool, device=pos_id.device))

        loss_seq_item = self.v1_seq_item_contrastive_task(seq_output, same_pos_id, interaction, pos_item_emb_type)
        loss_seq_seq = self.v1_seq_seq_contrastive_task(seq_output, same_pos_id, interaction, item_seq_type, item_seq_len_type, item_emb_list_type)

        # print("si,ss: " + f'{loss_seq_item}, {loss_seq_seq}')
        loss = loss_seq_item + self.lam * loss_seq_seq
        return seq_output, loss

    def groupdict_seq_contrastive_task(self, interaction, seq_output_h, seq_output_s, seq_output_l):
        self.group_dict.set_decay(self.train_epoch)
        loss = torch.zeros(1, device=seq_output_h.device)

        if self.cur_step == 0:
            self.group_dict.reset_cluster_size()

        if self.train_epoch >= 0 and self.train_epoch <= self.config["kmeans_epochs"]:
            if self.cur_step == 0:
                self.group_dict.set_dict_init(self.proto_dict[0])
            group_emb1, topk_idx1, sim_mtx1 = self.group_dict(seq_output_h)
            group_emb_l, topk_idx_l, sim_mtx_l = self.group_dict(seq_output_l)

        else:
            group_emb_h, topk_idx_h, sim_mtx_h = self.group_dict(seq_output_h)
            group_emb_l, topk_idx_l, sim_mtx_l = self.group_dict(seq_output_l)

            group_emb_proj1 = self.proj_head1_1(group_emb_h)
            group_emb_proj2 = self.proj_head1_1(group_emb_l)

            group_emb_loss1 = contrastive_loss('infonce', group_emb_proj1, group_emb_proj2,
                                               temperature=self.temperature, is_print="groupembCL")
            group_emb_loss2 = contrastive_loss('infonce', group_emb_proj2, group_emb_proj1,
                                               temperature=self.temperature)
            group_emb_loss = (group_emb_loss1 + group_emb_loss2) / 2

            proto_loss1 = F.mse_loss(seq_output_h, group_emb_proj1)
            proto_loss2 = F.mse_loss(seq_output_l, group_emb_proj2)
            protoloss = (proto_loss1 + proto_loss2) / 2
            loss = group_emb_loss + protoloss
        return loss


    def pretrain_all(self, interaction):
        seq_output_h, loss_h = self.v1_pretrain(interaction, "item_id", "item_id_list", "item_length", "item_emb_list", "pos_item_emb")
        seq_output_s, loss_s = self.v1_pretrain(interaction, "item_id_short", "item_id_list_short", "item_length_short", "item_emb_list_short", "pos_item_emb_short")
        seq_output_l, loss_l = self.v1_pretrain(interaction, "item_id_long", "item_id_list_long", "item_length_long", "item_emb_list_long", "pos_item_emb_long")

        loss_sl_ss = self.sl_seq_seq_contrastive_task(seq_output_h, seq_output_s, seq_output_l)
        loss_group = self.groupdict_seq_contrastive_task(interaction, seq_output_h, seq_output_s, seq_output_l)
        # print(loss_h, loss_s)
        return loss_h + (loss_s * 0.1 + loss_l) * 0.5 + loss_sl_ss * 0.1 + loss_group * 0.1
        # return loss_h
    def pretrain_kmeans(self, interaction, item_id_type, item_seq_type, item_seq_len_type, item_emb_list_type, pos_item_emb_type):
        item_seq = interaction[item_seq_type]
        item_seq_len = interaction[item_seq_len_type]
        item_emb_list = self.moe_adaptor(interaction[item_emb_list_type])
        seq_output = self.forward(item_seq, item_emb_list, item_seq_len)
        seq_output = F.normalize(seq_output, dim=1)
        return seq_output

    def pretrain_kmeans_all(self, interaction):
        seq_output_h = self.pretrain_kmeans(interaction, "item_id", "item_id_list", "item_length", "item_emb_list",
                                                "pos_item_emb")
        # seq_output_s = self.pretrain_kmeans(interaction, "item_id_short", "item_id_list_short", "item_length_short",
        #                                         "item_emb_list_short", "pos_item_emb_short")
        # seq_output_l = self.pretrain_kmeans(interaction, "item_id_long", "item_id_list_long", "item_length_long",
        #                                         "item_emb_list_long", "pos_item_emb_long")

        return seq_output_h



    def calculate_loss(self, interaction, proto_dict=[], epoch=0, cur_step=0, run_inference=False):
        self.train_epoch = epoch
        self.cur_step = cur_step
        self.proto_dict = proto_dict
        if self.train_stage == 'pretrain':
            if run_inference:
                return self.pretrain_kmeans_all(interaction)
            return self.pretrain_all(interaction)
        elif self.train_stage == 'finetune':
            return self.pretrain(interaction)

        # Loss for fine-tuning
        item_seq = interaction[self.ITEM_SEQ]
        item_seq_len = interaction[self.ITEM_SEQ_LEN]
        item_emb_list = self.moe_adaptor(self.plm_embedding(item_seq))
        seq_output = self.forward(item_seq, item_emb_list, item_seq_len)
        test_item_emb = self.moe_adaptor(self.plm_embedding.weight)
        if self.train_stage == 'transductive_ft':
            test_item_emb = test_item_emb + self.item_embedding.weight

        seq_output = F.normalize(seq_output, dim=1)
        test_item_emb = F.normalize(test_item_emb, dim=1)

        logits = torch.matmul(seq_output, test_item_emb.transpose(0, 1)) / self.temperature
        pos_items = interaction[self.POS_ITEM_ID]
        loss = self.loss_fct(logits, pos_items)


        return loss

    def full_sort_predict(self, interaction):
        item_seq = interaction[self.ITEM_SEQ]
        item_seq_len = interaction[self.ITEM_SEQ_LEN]
        item_emb_list = self.moe_adaptor(self.plm_embedding(item_seq))
        seq_output = self.forward(item_seq, item_emb_list, item_seq_len)
        test_items_emb = self.moe_adaptor(self.plm_embedding.weight)
        if self.train_stage == 'transductive_ft':
            test_items_emb = test_items_emb + self.item_embedding.weight

        seq_output = F.normalize(seq_output, dim=-1)
        test_items_emb = F.normalize(test_items_emb, dim=-1)

        scores = torch.matmul(seq_output, test_items_emb.transpose(0, 1))  # [B n_items]
        return scores
